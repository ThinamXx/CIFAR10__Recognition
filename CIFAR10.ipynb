{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1puEw4xU3FN6"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACzb2zyn2T4r"
      },
      "source": [
        "### **INITIALIZATION:**\n",
        "- I use these three lines of code on top of my each notebooks because it will help to prevent any problems while reloading the same project. And the third line of code helps to make visualization within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwA2hAIn2knc"
      },
      "source": [
        "#@ INITIALIZATION:\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngqa5UHg2nVD"
      },
      "source": [
        "**DOWNLOADING THE DEPENDENCIES:**\n",
        "- I have downloaded all the libraries and dependencies required for the project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9svNzYFV27CD"
      },
      "source": [
        "#@ DOWNLOADING THE LIBRARIES AND DEPENDENCIES:\n",
        "# !pip install -U d2l\n",
        "# !apt-get install p7zip-full\n",
        "\n",
        "import os, collections, math\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "ID = \"RECOG\"\n",
        "IMAGE_PATH = os.path.join(PROJECT_ROOT_DIR, \"Images\", ID)\n",
        "if not os.path.isdir(IMAGE_PATH):\n",
        "    os.makedirs(IMAGE_PATH)\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "  path = os.path.join(IMAGE_PATH, fig_id + \".\" + fig_extension)\n",
        "  print(\"Saving Figure\", fig_id)\n",
        "  if tight_layout:\n",
        "    plt.tight_layout()\n",
        "  plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1puEw4xU3FN6"
      },
      "source": [
        "### **OBTAINING AND ORGANIZING THE DATASET:**\n",
        "- I have used google colab for this project so the process of downloading and reading the data might be different in other platforms. I will use [**CIFAR-10 Object Recognition in Images**](https://www.kaggle.com/c/cifar-10) for this project. The dataset is divided into training set and test set. The training set contains 50,000 images. The images contains the categories such as planes, cars, birds, cats, deer, dogs, frogs, horses, boats and trucks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khnYzTCC6IKj"
      },
      "source": [
        "#@ ORGANIZING THE DATASET: UNCOMMENT BELOW: \n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Kaggle\"\n",
        "# %cd /content/drive/MyDrive/Kaggle\n",
        "# !kaggle competitions download -c cifar-10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6rbcp1N7xeO"
      },
      "source": [
        "#@ OBTAINING THE DATASET: \n",
        "d2l.DATA_HUB[\"CIFAR10\"] = (d2l.DATA_URL + \"kaggle_cifar10_tiny.zip\", \n",
        "                           '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')                  # Initializing the Dataset. \n",
        "demo = True                                                                             # Initialization. \n",
        "if demo: data_dir = d2l.download_extract(\"CIFAR10\")                                     # Initialization. \n",
        "else: data_dir = \"../Data/CIFAR10/\"                                                     # Initializaiton. "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww8OIeCqJF-w"
      },
      "source": [
        "**ORGANIZING THE DATASET:**\n",
        "- I will organize the datasets to facilitate model training and testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aAPXSne8I0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2597d2-1c60-482a-ba52-30ac4caea864"
      },
      "source": [
        "#@ ORGANIZING THE DATASET: \n",
        "def read_csv_labels(fname):                                                             # Returning names to Labels. \n",
        "  with open(fname, \"r\") as f:\n",
        "    lines = f.readlines()[1:]                                                           # Reading Lines. \n",
        "  tokens = [l.rstrip().split(\",\") for l in lines]\n",
        "  return dict(((name, label) for name, label in tokens))\n",
        "labels = read_csv_labels(os.path.join(data_dir, \"trainLabels.csv\"))                     # Implementation. \n",
        "print(f\"Training Examples: {len(labels)}\")                                              # Number of Training Examples. \n",
        "print(f\"Classes: {len(set(labels.values()))}\")                                          # Number of Classes. "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Examples: 1000\n",
            "Classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cac3kU-YIKlU"
      },
      "source": [
        "#@ ORGANIZING THE DATASET: \n",
        "def copyfile(filename, target_dir):                                                      # Copying File into Target Directory. \n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "  shutil.copy(filename, target_dir)\n",
        "#@ ORGANIZING THE DATASET: \n",
        "def reorg_train_valid(data_dir, labels, valid_ratio):\n",
        "  n = collections.Counter(labels.values()).most_common()[-1][1]                          # Number of examples per class. \n",
        "  n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
        "  label_count = {}\n",
        "  for train_file in os.listdir(os.path.join(data_dir, \"train\")):\n",
        "    label = labels[train_file.split(\".\")[0]]\n",
        "    fname = os.path.join(data_dir, \"train\", train_file)\n",
        "    copyfile(fname, os.path.join(data_dir, \"train_valid_test\", \"train_valid\", label))    # Copy to Train Valid. \n",
        "    if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "      copyfile(fname, os.path.join(data_dir, \"train_valid_test\", \"valid\", label))        # Copy to Valid. \n",
        "      label_count[label] = label_count.get(label, 0) + 1\n",
        "    else: \n",
        "      copyfile(fname, os.path.join(data_dir, \"train_valid_test\", \"train\", label))        # Copy to Train. \n",
        "  return n_valid_per_label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnzb5Mu_cn6k"
      },
      "source": [
        "- The reorg test function is used to organize the testing set to facilitate the reading during prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ydIjj_b2Z3"
      },
      "source": [
        "#@ ORGANIZING THE DATASET: \n",
        "def reorg_test(data_dir):                                                           # Initialization. \n",
        "  for test_file in os.listdir(os.path.join(data_dir, \"test\")):\n",
        "    copyfile(os.path.join(data_dir, \"test\", test_file), \n",
        "             os.path.join(data_dir, \"train_valid_test\", \"test\", \"unknown\"))         # Implementation of Function. "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCxsSpJceAfQ"
      },
      "source": [
        "#@ OBTAINING AND ORGANIZING THE DATASET: \n",
        "def reorg_cifar10_data(data_dir, valid_ratio):                                      # Obtaining and Organizing the Dataset. \n",
        "  labels = read_csv_labels(os.path.join(data_dir, \"trainLabels.csv\"))               # Implementation of Function. \n",
        "  reorg_train_valid(data_dir, labels, valid_ratio)                                  # Implementation of Function. \n",
        "  reorg_test(data_dir)                                                              # Implementation of Function. "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFYp4G0pfa5q"
      },
      "source": [
        "#@ INITIALIZING THE PARAMETERS: \n",
        "batch_size = 4 if demo else 128                                                     # Initializing Batchsize. \n",
        "valid_ratio = 0.1                                                                   # Initialization. \n",
        "reorg_cifar10_data(data_dir, valid_ratio)                                           # Obtaining and Organizing the Dataset. "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTItWww9gJg5"
      },
      "source": [
        "### **IMAGE AUGMENTATION:**\n",
        "- I will use image augmentation to cope with overfitting. The images are flipped at random and normalized. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5CrYNjQgB22"
      },
      "source": [
        "#@ IMPLEMENTATION OF IMAGE AUGMENTATION: TRAINING DATASET:  \n",
        "transform_train = torchvision.transforms.Compose([                                   # Initialization. \n",
        "                  torchvision.transforms.Resize(40),                                 # Resizing both Height and Width.\n",
        "                  torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0), \n",
        "                                                           ratio=(1.0, 1.0)),        # Cropping and Resizing. \n",
        "                  torchvision.transforms.RandomHorizontalFlip(),                     # Randomly Flipping Image. \n",
        "                  torchvision.transforms.ToTensor(),                                 # Converting into Tensors. \n",
        "                  torchvision.transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], \n",
        "                                                   std=[0.2023, 0.1994, 0.2010])])   # Normalization of RGB Channels. \n",
        "#@ IMPLEMENTATION OF IMAGE AUGMENTATION: TEST DATASET: \n",
        "transform_test = torchvision.transforms.Compose([\n",
        "                 torchvision.transforms.ToTensor(),                                  # Converting into Tensors. \n",
        "                 torchvision.transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], \n",
        "                                                   std=[0.2023, 0.1994, 0.2010])])   # Normalization of RGB Channels. "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75hajT7r7QQ8"
      },
      "source": [
        "### **READING THE DATASET:**\n",
        "- I will create the image folder dataset instance to read the organized dataset containing original image files where each example includes the image and label. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti3hlFxB7PMb"
      },
      "source": [
        "#@ READING THE DATASET: \n",
        "train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n",
        "    os.path.join(data_dir, \"train_valid_test\", folder), \n",
        "    transform = transform_train) for folder in [\"train\", \"train_valid\"]]                    # Initializing Training Dataset. \n",
        "#@ READING THE DATASET: \n",
        "valid_ds, test_ds = [torchvision.datasets.ImageFolder(\n",
        "    os.path.join(data_dir, \"train_valid_test\", folder), \n",
        "    transform = transform_test) for folder in [\"valid\", \"test\"]]                            # Initializing Test Dataset. "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ZfqqJu7PBa"
      },
      "source": [
        "#@ IMPLEMENTATION OF DATALOADER: \n",
        "train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
        "    dataset, batch_size, shuffle=True, drop_last=True) for dataset in (train_ds, \n",
        "                                                                       train_valid_ds)]      # Implementation of DataLoader. \n",
        "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=True, drop_last=True) # Implementation of DataLoader. \n",
        "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=True, drop_last=False)  # Implementation of DataLoader. "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYt_qwc6BoNn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}